---
title: 使用t-SNE进行预测的整合方案
date: '2018-01-24'
linkTitle: /2018/01/24/t-sne-prediction/
source: Jiaxiang Li's Blog
description: |-
  t-SNE是一种无监督学习， 虽然在可视化化中加入\(y\)变量的分类颜色，进行调参， 实现了半监督。 但是，实际上，没有办法像回归和决策树等进行一个\(\hat f\)的拟合， 这里提供一个整合方案。
  整合方案 假设有100个特征向量\(X=[x_1,\cdots,x_{100}]\)，通过t-SNE，降维到 两个维度\(\tilde y_1,\tilde y_2\)。 假设\(y=0,1\)。 通过进行调参，我们得到了尽可能分开\(y=0\)和\(y=1\)的两种情况。 我们导出\(\tilde y_1,\tilde y_2\)，数据满足\(R \in R^{m\times2}\)。 因为调参部分能够尽可能分开\(y=0\)和\(y=1\)的两种情况， 我们相信，任何模型都可以简单的fit出来，而且显著性很高。 t-SNE感觉是用来预测之前看变量的。 因此fit模型， \(\tilde y_1=f_1(X)\)和 \(\tilde y_2=f_2(X)\)。得到对应的beta系数，假设是用回归完成的， ...
disable_comments: true
---
t-SNE是一种无监督学习， 虽然在可视化化中加入\(y\)变量的分类颜色，进行调参， 实现了半监督。 但是，实际上，没有办法像回归和决策树等进行一个\(\hat f\)的拟合， 这里提供一个整合方案。
整合方案 假设有100个特征向量\(X=[x_1,\cdots,x_{100}]\)，通过t-SNE，降维到 两个维度\(\tilde y_1,\tilde y_2\)。 假设\(y=0,1\)。 通过进行调参，我们得到了尽可能分开\(y=0\)和\(y=1\)的两种情况。 我们导出\(\tilde y_1,\tilde y_2\)，数据满足\(R \in R^{m\times2}\)。 因为调参部分能够尽可能分开\(y=0\)和\(y=1\)的两种情况， 我们相信，任何模型都可以简单的fit出来，而且显著性很高。 t-SNE感觉是用来预测之前看变量的。 因此fit模型， \(\tilde y_1=f_1(X)\)和 \(\tilde y_2=f_2(X)\)。得到对应的beta系数，假设是用回归完成的， ...