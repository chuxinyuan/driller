---
title: F1分数为什么可以看不平衡样本的预测能力
date: '2017-12-27'
linkTitle: /2017/12/27/f1/
source: Jiaxiang Li's Blog
description: |-
  F1分数可以衡量模型对少类用户的预测效果。
  实际上，遇到unbalanced data，就是一种分类下小的可怜，例如5%的，1%的，理解Precision、F1-Score、KS的作用，关键在于\(FP\)， 具体混淆矩阵可以看这里， KS函数 - A Hugo website。
  直接说干货。 比如，一个分类下，\(y=1\)占有99%的样本，拍脑袋的话，全部\(\hat y = 1\)也有99%的\(Acc\)了。
  \[Acc = \frac{TP+TN}{TP+FN+TN+FP}\]
  但是，这么中和下这种偏度呢？ 关键之处是，\(FP\)太多了，太多的\(TN\)被搞成了\(FP\)，因此\(FP \uparrow\)。
  就是Precision含有这一项，
  \[Precision = \frac{TP}{TP+FP}\]，当\(FP \uparrow\)时，显然在下降了。
  另外，F1-Score是Recall和Precision的调和平均数，
  \[F1= ...
disable_comments: true
---
F1分数可以衡量模型对少类用户的预测效果。
实际上，遇到unbalanced data，就是一种分类下小的可怜，例如5%的，1%的，理解Precision、F1-Score、KS的作用，关键在于\(FP\)， 具体混淆矩阵可以看这里， KS函数 - A Hugo website。
直接说干货。 比如，一个分类下，\(y=1\)占有99%的样本，拍脑袋的话，全部\(\hat y = 1\)也有99%的\(Acc\)了。
\[Acc = \frac{TP+TN}{TP+FN+TN+FP}\]
但是，这么中和下这种偏度呢？ 关键之处是，\(FP\)太多了，太多的\(TN\)被搞成了\(FP\)，因此\(FP \uparrow\)。
就是Precision含有这一项，
\[Precision = \frac{TP}{TP+FP}\]，当\(FP \uparrow\)时，显然在下降了。
另外，F1-Score是Recall和Precision的调和平均数，
\[F1= ...