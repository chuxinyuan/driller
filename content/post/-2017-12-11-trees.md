---
title: Trees分支学习
date: '2017-12-11'
linkTitle: /2017/12/11/trees/
source: Jiaxiang Li's Blog
description: |-
  数学 · 决策树（一）· 混乱程度 ， \(pi \in [0,1] \to H(Y) \geq 0\) ， 所以最小值是0，这样的话，说明在一个分支内，异质性很小。 ， 这个可以总结一下。 决策树理论部分可以参考 Brett Lantz Machine Learning with R - Second Edition.pdf的126页附近。 决策树的解释意思就是 它会给出一个可能性，如果你的答案是\(1\)或\(0\)，那么答案就是\(1\)的概率为\(p\)，\(0\)的概率为\(1-p\)。
  在看完决策树后，可以了解一下随机森林，具体的之后我再准备给你。他们之间大致的关系如下图。 {"x":{"diagram":"\ndigraph boxes_and_circles {\n\n决策树\nBagging\n随机森林\nboosting\nxgboosting\n\n决策树 - Bagging [label = ...
disable_comments: true
---
数学 · 决策树（一）· 混乱程度 ， \(pi \in [0,1] \to H(Y) \geq 0\) ， 所以最小值是0，这样的话，说明在一个分支内，异质性很小。 ， 这个可以总结一下。 决策树理论部分可以参考 Brett Lantz Machine Learning with R - Second Edition.pdf的126页附近。 决策树的解释意思就是 它会给出一个可能性，如果你的答案是\(1\)或\(0\)，那么答案就是\(1\)的概率为\(p\)，\(0\)的概率为\(1-p\)。
在看完决策树后，可以了解一下随机森林，具体的之后我再准备给你。他们之间大致的关系如下图。 {"x":{"diagram":"\ndigraph boxes_and_circles {\n\n决策树\nBagging\n随机森林\nboosting\nxgboosting\n\n决策树 - Bagging [label = ...