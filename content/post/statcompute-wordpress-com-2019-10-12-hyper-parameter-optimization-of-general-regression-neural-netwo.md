---
title: Hyper-Parameter Optimization of General Regression Neural Networks
date: '2019-10-13'
linkTitle: https://statcompute.wordpress.com/2019/10/12/hyper-parameter-optimization-of-general-regression-neural-networks/
source: Yet Another Blog in Statistical Computing
description: A major advantage of General Regression Neural Networks (GRNN) over other
  types of neural networks is that there is only a single hyper-parameter, namely
  the sigma. In the previous post (https://statcompute.wordpress.com/2019/07/06/latin-hypercube-sampling-in-hyper-parameter-optimization),
  I’ve shown how to use the random search strategy to find a close-to-optimal value
  of the sigma by using various random number generators, including ...
disable_comments: true
---
A major advantage of General Regression Neural Networks (GRNN) over other types of neural networks is that there is only a single hyper-parameter, namely the sigma. In the previous post (https://statcompute.wordpress.com/2019/07/06/latin-hypercube-sampling-in-hyper-parameter-optimization), I’ve shown how to use the random search strategy to find a close-to-optimal value of the sigma by using various random number generators, including ...